{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# KANs Example Revisited\n",
        "\n",
        "Source: https://github.com/KindXiaoming/pykan/blob/master/tutorials/Example_2_deep_formula.ipynb\n",
        "\n",
        "## \"With a bit noise in training dataset, it becomes a totally different story!\""
      ],
      "metadata": {
        "id": "Oa_wQm4BTSKs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaC0bshQ7JoI",
        "outputId": "c1550e97-a31d-4114-de3b-0755e4459707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pykan\n",
            "  Downloading pykan-0.0.5-py3-none-any.whl (33 kB)\n",
            "Installing collected packages: pykan\n",
            "Successfully installed pykan-0.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install pykan"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XO9hkkCrXiyP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset2(f,\n",
        "                   n_var=2,\n",
        "                   ranges = [-1,1],\n",
        "                   train_num=1000,\n",
        "                   test_num=1000,\n",
        "                   normalize_input=True,\n",
        "                   normalize_label=True,\n",
        "                   add_noise=True,  # add noise\n",
        "                   noise_level=0.1,\n",
        "                   device='cpu',\n",
        "                   seed=0):\n",
        "    '''\n",
        "    create dataset\n",
        "\n",
        "    Args:\n",
        "    -----\n",
        "        f : function\n",
        "            the symbolic formula used to create the synthetic dataset\n",
        "        ranges : list or np.array; shape (2,) or (n_var, 2)\n",
        "            the range of input variables. Default: [-1,1].\n",
        "        train_num : int\n",
        "            the number of training samples. Default: 1000.\n",
        "        test_num : int\n",
        "            the number of test samples. Default: 1000.\n",
        "        normalize_input : bool\n",
        "            If True, apply normalization to inputs. Default: False.\n",
        "        normalize_label : bool\n",
        "            If True, apply normalization to labels. Default: False.\n",
        "        device : str\n",
        "            device. Default: 'cpu'.\n",
        "        seed : int\n",
        "            random seed. Default: 0.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "        dataset : dic\n",
        "            Train/test inputs/labels are dataset['train_input'], dataset['train_label'],\n",
        "                        dataset['test_input'], dataset['test_label']\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    >>> f = lambda x: torch.exp(torch.sin(torch.pi*x[:,[0]]) + x[:,[1]]**2)\n",
        "    >>> dataset = create_dataset(f, n_var=2, train_num=100)\n",
        "    >>> dataset['train_input'].shape\n",
        "    torch.Size([100, 2])\n",
        "    '''\n",
        "\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    if len(np.array(ranges).shape) == 1:\n",
        "        ranges = np.array(ranges * n_var).reshape(n_var,2)\n",
        "    else:\n",
        "        ranges = np.array(ranges)\n",
        "\n",
        "    train_input = torch.zeros(train_num, n_var)\n",
        "    test_input = torch.zeros(test_num, n_var)\n",
        "    for i in range(n_var):\n",
        "        train_input[:,i] = torch.rand(train_num,)*(ranges[i,1]-ranges[i,0])+ranges[i,0]\n",
        "        test_input[:,i] = torch.rand(test_num,)*(ranges[i,1]-ranges[i,0])+ranges[i,0]\n",
        "\n",
        "\n",
        "    train_label = f(train_input)\n",
        "    test_label = f(test_input)\n",
        "\n",
        "\n",
        "    def normalize(data, mean, std):\n",
        "            return (data-mean)/std\n",
        "\n",
        "    if normalize_input == True:\n",
        "        mean_input = torch.mean(train_input, dim=0, keepdim=True)\n",
        "        std_input = torch.std(train_input, dim=0, keepdim=True)\n",
        "        train_input = normalize(train_input, mean_input, std_input)\n",
        "        test_input = normalize(test_input, mean_input, std_input)\n",
        "\n",
        "    if normalize_label == True:\n",
        "        mean_label = torch.mean(train_label, dim=0, keepdim=True)\n",
        "        std_label = torch.std(train_label, dim=0, keepdim=True)\n",
        "        train_label = normalize(train_label, mean_label, std_label)\n",
        "        test_label = normalize(test_label, mean_label, std_label)\n",
        "\n",
        "    if add_noise:\n",
        "        noise = torch.randn_like(test_label) * noise_level\n",
        "        test_label += noise\n",
        "\n",
        "    dataset = {}\n",
        "    dataset['train_input'] = train_input.to(device)\n",
        "    dataset['test_input'] = test_input.to(device)\n",
        "\n",
        "    dataset['train_label'] = train_label.to(device)\n",
        "    dataset['test_label'] = test_label.to(device)\n",
        "\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "HqpTRwDOHDf8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kan import KAN, create_dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# create a KAN: 2D inputs, 1D output, and 5 hidden neurons. cubic spline (k=3), 5 grid intervals (grid=5).\n",
        "model = KAN(width=[4,2,1,1], grid=3, k=3, seed=0)\n",
        "f = lambda x: torch.exp((torch.sin(torch.pi*(x[:,[0]]**2+x[:,[1]]**2))+torch.sin(torch.pi*(x[:,[2]]**2+x[:,[3]]**2)))/2)\n",
        "dataset = create_dataset2(f, n_var=4, train_num=1000, test_num=1000, noise_level=0.1)\n",
        "\n",
        "image_folder = 'video_img'\n",
        "\n",
        "# train the model\n",
        "#model.train(dataset, opt=\"LBFGS\", steps=20, lamb=1e-3, lamb_entropy=2.);\n",
        "model.train(dataset, opt=\"LBFGS\", steps=50, lamb=5e-5, lamb_entropy=2., save_fig=True, beta=10,\n",
        "            in_vars=[r'$x_1$', r'$x_2$', r'$x_3$', r'$x_4$'],\n",
        "            out_vars=[r'${\\rm exp}({\\rm sin}(x_1^2+x_2^2)+{\\rm sin}(x_3^2+x_4^2))$'],\n",
        "            img_folder=image_folder);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6WaqV6c9Hx_",
        "outputId": "ad364a51-b9fc-4022-9419-fc65834de254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train loss: 1.09e-02 | test loss: 1.01e-01 | reg: 1.03e+01 : 100%|██| 50/50 [03:12<00:00,  3.86s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import moviepy.video.io.ImageSequenceClip # moviepy == 1.0.3\n",
        "\n",
        "video_name='video'\n",
        "fps=5\n",
        "\n",
        "fps = fps\n",
        "files = os.listdir(image_folder)\n",
        "train_index = []\n",
        "for file in files:\n",
        "    if file[0].isdigit() and file.endswith('.jpg'):\n",
        "        train_index.append(int(file[:-4]))\n",
        "\n",
        "train_index = np.sort(train_index)\n",
        "\n",
        "image_files = [image_folder+'/'+str(train_index[index])+'.jpg' for index in train_index]\n",
        "\n",
        "clip = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(image_files, fps=fps)\n",
        "clip.write_videofile(video_name+'.mp4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gn7MXIpA9RHG",
        "outputId": "0b51987c-833e-4c49-87ca-7b2d1575b56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Building video video.mp4.\n",
            "Moviepy - Writing video video.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready video.mp4\n"
          ]
        }
      ]
    }
  ]
}